{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78ae1834-ae30-4799-8aa4-5786ee49d845",
   "metadata": {},
   "source": [
    "### Baseline –º–æ–¥–µ–ª—å –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π –ø–æ –∫–µ–π—Å—É –æ—Ç Rutube.\n",
    "–ü–æ—Å–∫–æ–ª—å–∫—É –Ω–∞–º –Ω—É–∂–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ NER, –º–æ–∂–Ω–æ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –ø–æ–º–æ—â—å—é —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π, –≤ –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ - Bert.\n",
    "–î–∞–Ω–Ω—ã–µ –≤—ã —É–∂–µ –ø–æ–ª—É—á–∏–ª–∏  - —ç—Ç–æ —Ä–∞–∑–º–µ—Ç–∫–∞, —Å–¥–µ–ª–∞–Ω–Ω–∞—è –Ω–∞ –¢–æ–ª–æ–∫–µ, –æ–Ω–∞ –Ω–µ –∏–¥–µ–∞–ª—å–Ω–∞, –Ω–æ —ç—Ç–æ —á–∞—Å—Ç—å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–π –∑–∞–¥–∞—á–∏, —Å –∫–æ—Ç–æ—Ä–æ–π –º–æ–∂–Ω–æ —Å—Ç–æ–ª–∫–Ω—É—Ç—å—Å—è –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏. \n",
    "\n",
    "–ù–µ–±–æ–ª—å—à–æ–µ –≤–≤–µ–¥–µ–Ω–∏–µ –≤ NER https://habr.com/ru/companies/contentai/articles/449514/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34f651cc-6e8c-431c-a84e-2e7d310c9d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —Å—á–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"ner_data_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5105af13-906b-43cc-b795-bdae96d030ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_info</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;–ù–ê–ó–í–ê–ù–ò–ï:&gt; –ê–≥–µ–Ω—Ç 117: –ò–∑ –ê—Ñ—Ä–∏–∫–∏ —Å –ª—é–±–æ–≤—å—é ‚Äî –†...</td>\n",
       "      <td>{\"label\":\"–ª–æ–∫–∞—Ü–∏—è\"\\,\"offset\":26\\,\"length\":6\\,\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;–ù–ê–ó–í–ê–ù–ò–ï:&gt; –ö–æ–ª–µ–Ω–≤–∞–ª –ò–Ω—Ñ–∏–Ω–∏—Ç–∏ –ö—É –∏–∫—Å 56= 5.6 V...</td>\n",
       "      <td>{\"label\":\"–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è\"\\,\"offset\":196\\,\"length\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;–ù–ê–ó–í–ê–ù–ò–ï:&gt; –í–´–ó–û–í –î–ï–ú–û–ù–ê = –í—ã–∑–≤–∞–ª –°–µ—Ä–æ–≥–æ –ß–µ–ª–æ–≤...</td>\n",
       "      <td>{\"label\":\"–Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞\"\\,\"offset\":12\\,\"len...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;–ù–ê–ó–í–ê–ù–ò–ï:&gt; –î–æ–≤–æ–µ–Ω–Ω–∞—è –Ω–µ–º–µ—Ü–∫–∞—è –∫–∏—Ä—Ö–∞ –≤ –ö–∞–ª–∏–Ω–∏–Ω...</td>\n",
       "      <td>{\"label\":\"–Ω–µ –Ω–∞–π–¥–µ–Ω–æ\"\\,\"offset\":162\\,\"length\":...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;–ù–ê–ó–í–ê–ù–ò–ï:&gt; \"–°–ø–∞—Ä—Ç–∞–∫—É\" –ø–æ–º–æ–≥–ª–∏ —Å—É–¥—å–∏? –õ–æ–∫–æ–º–æ—Ç–∏...</td>\n",
       "      <td>{\"label\":\"–∫–æ–º–∞–Ω–¥–∞\"\\,\"offset\":13\\,\"length\":8\\,\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          video_info  \\\n",
       "0  <–ù–ê–ó–í–ê–ù–ò–ï:> –ê–≥–µ–Ω—Ç 117: –ò–∑ –ê—Ñ—Ä–∏–∫–∏ —Å –ª—é–±–æ–≤—å—é ‚Äî –†...   \n",
       "1  <–ù–ê–ó–í–ê–ù–ò–ï:> –ö–æ–ª–µ–Ω–≤–∞–ª –ò–Ω—Ñ–∏–Ω–∏—Ç–∏ –ö—É –∏–∫—Å 56= 5.6 V...   \n",
       "2  <–ù–ê–ó–í–ê–ù–ò–ï:> –í–´–ó–û–í –î–ï–ú–û–ù–ê = –í—ã–∑–≤–∞–ª –°–µ—Ä–æ–≥–æ –ß–µ–ª–æ–≤...   \n",
       "3  <–ù–ê–ó–í–ê–ù–ò–ï:> –î–æ–≤–æ–µ–Ω–Ω–∞—è –Ω–µ–º–µ—Ü–∫–∞—è –∫–∏—Ä—Ö–∞ –≤ –ö–∞–ª–∏–Ω–∏–Ω...   \n",
       "4  <–ù–ê–ó–í–ê–ù–ò–ï:> \"–°–ø–∞—Ä—Ç–∞–∫—É\" –ø–æ–º–æ–≥–ª–∏ —Å—É–¥—å–∏? –õ–æ–∫–æ–º–æ—Ç–∏...   \n",
       "\n",
       "                                            entities  \n",
       "0  {\"label\":\"–ª–æ–∫–∞—Ü–∏—è\"\\,\"offset\":26\\,\"length\":6\\,\"...  \n",
       "1  {\"label\":\"–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è\"\\,\"offset\":196\\,\"length\"...  \n",
       "2  {\"label\":\"–Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞\"\\,\"offset\":12\\,\"len...  \n",
       "3  {\"label\":\"–Ω–µ –Ω–∞–π–¥–µ–Ω–æ\"\\,\"offset\":162\\,\"length\":...  \n",
       "4  {\"label\":\"–∫–æ–º–∞–Ω–¥–∞\"\\,\"offset\":13\\,\"length\":8\\,\"...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "902ad843-b9a6-4aeb-b283-6590444aea06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –¥–∞–Ω–Ω—ã–µ —Å–ø–∞—Ä—Å–µ–Ω—ã —Å –¢–æ–ª–æ–∫–∏, –ø–æ—ç—Ç–æ–º—É –º–æ–≥—É—Ç –∏–º–µ—Ç—å –ø—Ä–æ–±–ª–µ–º—ã —Å —Å–∏–º–≤–æ–ª–∞–º–∏ –∏ –∏—Ö –Ω—É–∂–Ω–æ –∏–∑–±–µ–∂–∞—Ç—å, \n",
    "# —É–¥–∞–ª–∏—Ç—å –ª–∏—à–Ω–∏–µ '\\' –Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –∏–∑ str –≤ —Å–ø–∏—Å–æ–∫ dict-–æ–≤\n",
    "import json\n",
    "df = data.copy()\n",
    "df['entities'] = df['entities'].apply(lambda l: l.replace('\\,', ',')if isinstance(l, str) else l)\n",
    "df['entities'] = df['entities'].apply(lambda l: l.replace('\\\\\\\\', '\\\\')if isinstance(l, str) else l)\n",
    "df['entities'] = df['entities'].apply(lambda l: '[' + l + ']'if isinstance(l, str) else l)\n",
    "df['entities'] = df['entities'].apply(lambda l: json.loads(l)if isinstance(l, str) else l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8768495c-c2a5-4c74-a5de-a60bbd60898f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_info</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;–ù–ê–ó–í–ê–ù–ò–ï:&gt; –ê–≥–µ–Ω—Ç 117: –ò–∑ –ê—Ñ—Ä–∏–∫–∏ —Å –ª—é–±–æ–≤—å—é ‚Äî –†...</td>\n",
       "      <td>[{'label': '–ª–æ–∫–∞—Ü–∏—è', 'offset': 26, 'length': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;–ù–ê–ó–í–ê–ù–ò–ï:&gt; –ö–æ–ª–µ–Ω–≤–∞–ª –ò–Ω—Ñ–∏–Ω–∏—Ç–∏ –ö—É –∏–∫—Å 56= 5.6 V...</td>\n",
       "      <td>[{'label': '–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è', 'offset': 196, 'leng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;–ù–ê–ó–í–ê–ù–ò–ï:&gt; –í–´–ó–û–í –î–ï–ú–û–ù–ê = –í—ã–∑–≤–∞–ª –°–µ—Ä–æ–≥–æ –ß–µ–ª–æ–≤...</td>\n",
       "      <td>[{'label': '–Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞', 'offset': 12, '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          video_info  \\\n",
       "0  <–ù–ê–ó–í–ê–ù–ò–ï:> –ê–≥–µ–Ω—Ç 117: –ò–∑ –ê—Ñ—Ä–∏–∫–∏ —Å –ª—é–±–æ–≤—å—é ‚Äî –†...   \n",
       "1  <–ù–ê–ó–í–ê–ù–ò–ï:> –ö–æ–ª–µ–Ω–≤–∞–ª –ò–Ω—Ñ–∏–Ω–∏—Ç–∏ –ö—É –∏–∫—Å 56= 5.6 V...   \n",
       "2  <–ù–ê–ó–í–ê–ù–ò–ï:> –í–´–ó–û–í –î–ï–ú–û–ù–ê = –í—ã–∑–≤–∞–ª –°–µ—Ä–æ–≥–æ –ß–µ–ª–æ–≤...   \n",
       "\n",
       "                                            entities  \n",
       "0  [{'label': '–ª–æ–∫–∞—Ü–∏—è', 'offset': 26, 'length': ...  \n",
       "1  [{'label': '–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è', 'offset': 196, 'leng...  \n",
       "2  [{'label': '–Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞', 'offset': 12, '...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce7c226-ba06-4b25-8e7c-1423f3d49e00",
   "metadata": {},
   "source": [
    "#### –û—Ä–∏–≥–∏–Ω–∞–ª —Ç—É—Ç–æ—Ä–∏–∞–ª–∞ –Ω–∞ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –º–æ–∂–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Ç—É—Ç https://gist.github.com/avidale/cacf235aebeaaf4c578389e1146c3c57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee336880-48fd-4c3c-9b84-4f9487d5d74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –¢–µ–ø–µ—Ä—å –∏–∑ –Ω–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–∞–º –Ω—É–∂–Ω–æ –∏–∑–≤–ª–µ—á—å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞ (—Ç–æ–∫–µ–Ω–∞) –µ–≥–æ —Ç–µ–≥ (label) –∏–∑ —Ä–∞–∑–º–µ—Ç–∫–∏, —á—Ç–æ–±—ã –ø–æ—Ç–æ–º –ø—Ä–µ–¥–∞—Ç—å –≤ –º–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤\n",
    "from razdel import tokenize\n",
    "\n",
    "def extract_labels(item):\n",
    "    \n",
    "    # –≤–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è —É–¥–æ–±–Ω—ã–º —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–æ–º –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ razdel, \n",
    "    # –æ–Ω–∞ –ø–æ–º–∏–º–æ —Ä–∞–∑–±–∏–µ–Ω–∏—è –Ω–∞ —Å–ª–æ–≤–∞, —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤–∞–∂–Ω—ã–µ –¥–ª—è –Ω–∞—Å —á–∏—Å–ª–∞ - –Ω–∞—á–∞–ª–æ –∏ –∫–æ–Ω–µ—Ü —Å–ª–æ–≤–∞ –≤ —Ç–æ–∫–µ–Ω–∞—Ö\n",
    "    \n",
    "    raw_toks = list(tokenize(item['video_info']))\n",
    "    words = [tok.text for tok in raw_toks]\n",
    "    # –ø—Ä–∏—Å–≤–æ–∏–º –¥–ª—è –Ω–∞—á–∞–ª–∞ –∫–∞–∂–¥–æ–º—É —Å–ª–æ–≤—É —Ç–µ–≥ '–û' - —Ç–µ–≥, –æ–∑–Ω–∞—á–∞—é—â–∏–π –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ NER-–∞\n",
    "    word_labels = ['O'] * len(raw_toks)\n",
    "    char2word = [None] * len(item['video_info'])\n",
    "    # —Ç–∞–∫ –∫–∞–∫ NER –º–æ–∂–µ–º —Å–æ—Å—Ç–∞—è—Ç—å –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–ª–æ–≤, —Ç–æ –Ω–∞–º –Ω—É–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —ç—Ç—É –∏–Ω—Ñ–æ—Ä—Ü–∏—é\n",
    "    for i, word in enumerate(raw_toks):\n",
    "        char2word[word.start:word.stop] = [i] * len(word.text)\n",
    "\n",
    "    labels = item['entities']\n",
    "    if isinstance(labels, dict):\n",
    "        labels = [labels]\n",
    "    if labels is not None:\n",
    "        for e in labels:\n",
    "            if e['label'] != '–Ω–µ –Ω–∞–π–¥–µ–Ω–æ':\n",
    "                e_words = sorted({idx for idx in char2word[e['offset']:e['offset']+e['length']] if idx is not None})\n",
    "                if e_words:\n",
    "                    word_labels[e_words[0]] = 'B-' + e['label']\n",
    "                    for idx in e_words[1:]:\n",
    "                        word_labels[idx] = 'I-' + e['label']\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "        return {'tokens': words, 'tags': word_labels}\n",
    "    else: return {'tokens': words, 'tags': word_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e2d3224-bd70-4a99-bdb3-fee8945ce2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['<', '–ù–ê–ó–í–ê–ù–ò–ï', ':', '>', '–ê–≥–µ–Ω—Ç', '117', ':', '–ò–∑', '–ê—Ñ—Ä–∏–∫–∏', '—Å', '–ª—é–±–æ–≤—å—é', '‚Äî', '–†—É—Å—Å–∫–∏–π', '—Ç–∏–∑–µ—Ä', '=', '—Ç—Ä–µ–π–ª–µ—Ä', '(', '2021', ')', '<', '–û–ü–ò–°–ê–ù–ò–ï', ':', '>', '–õ—É—á—à–∏–π', 'Telegram', '–∫–∞–Ω–∞–ª', '–æ', '–∫–∏–Ω–æ', '<', 'LINK', '>', '–°–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤–æ', '<', 'LINK', '>', '–î–∞—Ç–∞', '–≤—ã—Ö–æ–¥–∞', '26', '–∞–≤–≥—É—Å—Ç–∞', '2021', '–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ', '–Ω–∞–∑–≤–∞–Ω–∏–µ', ':', 'OSS', '117', ':', 'Alerte', 'rouge', 'en', 'Afrique', 'noire', '–°—Ç—Ä–∞–Ω–∞', ':', '–§—Ä–∞–Ω—Ü–∏—è', '–†–µ–∂–∏—Å—Å–µ—Ä', ':', '–ù–∏–∫–æ–ª—è', '–ë–µ–¥–æ—Å', '–ñ–∞–Ω—Ä', ':', '–±–æ–µ–≤–∏–∫', ',', '–∫–æ–º–µ–¥–∏—è', '–í', '–≥–ª–∞–≤–Ω—ã—Ö', '—Ä–æ–ª—è—Ö', ':', '–ñ–∞–Ω', '–î—é–∂–∞—Ä–¥–µ–Ω', ',', '–ü—å–µ—Ä', '–ù–∏–Ω—ç', ',', '–ú–µ–ª–æ–¥–∏', '–ö–∞—Å—Ç–∞', ',', '–ù–∞—Ç–∞—à–∞', '–õ–∏–Ω–¥–∏–Ω–∂–µ—Ä', ',', '–í–ª–∞–¥–∏–º–∏—Ä', '–ò–æ—Ä–¥–∞–Ω–æ–≤', ',', '–§–∞—Ç—É', '–ù', '‚Äô', '–î–∏–∞–π–µ', ',', '–ü–æ–ª', '–£–∞–π—Ç', '–ú–∏—Ä', '–∏–∑–º–µ–Ω–∏–ª—Å—è', '.', '–û–Ω', '–Ω–µ—Ç', '.', '–°—É–¥—å–±–∞', '–∑–∞–Ω–æ—Å–∏—Ç', '–ª–µ–≥–µ–Ω–¥–∞—Ä–Ω–æ–≥–æ', '–ê–≥–µ–Ω—Ç–∞', '117', '–≤', '–ê—Ñ—Ä–∏–∫—É', ',', '–≥–¥–µ', '–≥–æ—Ä—è—á–µ–µ', '–ø—É—Å—Ç—ã–Ω–∏', '—Ç–æ–ª—å–∫–æ', '–∂–µ–Ω—â–∏–Ω—ã', '.', '–í–æ–æ—Ä—É–∂–µ–Ω–Ω—ã–π', '–Ω–µ–∏—Å—Å—è–∫–∞–µ–º–æ–π', '—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é', '–≤', '—Å–µ–±–µ', '–∏', '—É–±–∏–π—Å—Ç–≤–µ–Ω–Ω–æ–π', '—Ö–∞—Ä–∏–∑–º–æ–π', ',', '–æ–Ω', '–º–æ–∂–µ—Ç', '—Å–ø—Ä–∞–≤–∏—Ç—å—Å—è', '—Å–æ', '–≤—Å–µ–º–∏', '–≤—Ä–∞–≥–∞–º–∏', ',', '–∫—Ä–æ–º–µ', '—Å–∞–º–æ–≥–æ', '—Å–µ–±—è', '.', '–ü–æ', '–≤–æ–ø—Ä–æ—Å–∞–º', '–∞–≤—Ç–æ—Ä—Å–∫–æ–≥–æ', '–ø—Ä–∞–≤–∞', ',', '–ø–æ–∂–∞–ª—É–π—Å—Ç–∞', ',', '—Å–≤—è–∂–∏—Ç–µ—Å—å', '—Å', '–Ω–∞–º–∏', '–ø–æ', '–∞–¥—Ä–µ—Å—É', ':', '<', 'AT', '>'], 'tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-–ª–æ–∫–∞—Ü–∏—è', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-–î–∞—Ç–∞', 'I-–î–∞—Ç–∞', 'I-–î–∞—Ç–∞', 'O', 'O', 'O', 'B-–Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞', 'I-–Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞', 'I-–Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞', 'I-–Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞', 'I-–Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞', 'I-–Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞', 'I-–Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞', 'I-–Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞', 'O', 'O', 'B-–ª–æ–∫–∞—Ü–∏—è', 'O', 'O', 'B-–ø–µ—Ä—Å–æ–Ω–∞', 'I-–ø–µ—Ä—Å–æ–Ω–∞', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-–ø–µ—Ä—Å–æ–Ω–∞', 'I-–ø–µ—Ä—Å–æ–Ω–∞', 'O', 'B-–ø–µ—Ä—Å–æ–Ω–∞', 'I-–ø–µ—Ä—Å–æ–Ω–∞', 'O', 'B-–ø–µ—Ä—Å–æ–Ω–∞', 'I-–ø–µ—Ä—Å–æ–Ω–∞', 'O', 'B-–ø–µ—Ä—Å–æ–Ω–∞', 'I-–ø–µ—Ä—Å–æ–Ω–∞', 'O', 'B-–ø–µ—Ä—Å–æ–Ω–∞', 'I-–ø–µ—Ä—Å–æ–Ω–∞', 'O', 'B-–ø–µ—Ä—Å–æ–Ω–∞', 'I-–ø–µ—Ä—Å–æ–Ω–∞', 'I-–ø–µ—Ä—Å–æ–Ω–∞', 'I-–ø–µ—Ä—Å–æ–Ω–∞', 'O', 'B-–ø–µ—Ä—Å–æ–Ω–∞', 'I-–ø–µ—Ä—Å–æ–Ω–∞', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-–ª–æ–∫–∞—Ü–∏—è', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']}\n"
     ]
    }
   ],
   "source": [
    "print(extract_labels(df.iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43db9d6-76f9-4f24-87ce-bea724a238a9",
   "metadata": {},
   "source": [
    "### –û–±—Ä–∞–±–æ—Ç–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç –∏ —Ä–∞–∑–æ–±—å–µ–º –Ω–∞ —Ç—Ä–µ–π–Ω –∏ —Ç–µ—Å—Ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fea76082-efcc-44da-ba3c-7dd466d3ecb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "ner_data = [extract_labels(item) for i, item in df.iterrows()]\n",
    "ner_train, ner_test = train_test_split(ner_data, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f181346-579e-4804-975a-f6133a86a985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4812</th>\n",
       "      <td>[&lt;, –ù–ê–ó–í–ê–ù–ò–ï, :, &gt;, –°–∏—Å—Ç–µ–º–∞, –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è, –±–∏–∑–Ω–µ—Å, —Å, WorldVentures, –æ—Ç, –ê–ª–µ–Ω—ã, –ê–Ω—Ç–æ–Ω–µ–Ω–∫–æ, &lt;, –û–ü–ò–°–ê–ù–ò–ï, :, &gt;, –î–æ, –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–≥–æ, –æ—Ç–∫—Ä—ã—Ç–∏—è, –∫–æ–º–ø–∞–Ω–∏–∏, WorldVentures, –≤, –†–æ—Å—Å–∏–∏, –æ—Å—Ç–∞–ª–æ—Å—å, —Å–æ–≤—Å–µ–º, –Ω–µ–º–Ω–æ–≥–æ, –≤—Ä–µ–º–µ–Ω–∏, ., –ü—Ä–∏–º–µ–Ω—è—è, –ø—Ä–æ—Å—Ç—É—é, –∏, –¥—É–ø–ª–∏—Ü–∏—Ä—É–µ–º—É—é, —Å–∏—Å—Ç–µ–º—É, –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è, –±–∏–∑–Ω–µ—Å–∞, ,, –º–æ–∂–Ω–æ, –∑–∞, –∫–æ—Ä–æ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, B-–ø–µ—Ä—Å–æ–Ω–∞, O, B-–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è, I-–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è, O, O, O, O, O, O, O, O, B-–ø–µ—Ä—Å–æ–Ω–∞, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-–ø–µ—Ä—Å–æ–Ω–∞, O, O, B-–ø–µ—Ä—Å–æ–Ω–∞, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>[&lt;, –ù–ê–ó–í–ê–ù–ò–ï, :, &gt;, –•—Ä—É—Å—Ç–∞–ª—å–Ω–æ–µ, —Å—á–∞—Å—Ç—å–µ, 1, =, 4, —Å–µ—Ä–∏—è, (, –ú–µ–ª–æ–¥—Ä–∞–º–∞, 2021, ), –æ–±–∑–æ—Ä, ,, –¥–∞—Ç–∞, –≤—ã—Ö–æ–¥–∞, &lt;, –û–ü–ò–°–ê–ù–ò–ï, :, &gt;, –ü—Ä–µ–º—å–µ—Ä–∞, 2021, \", –•—Ä—É—Å—Ç–∞–ª—å–Ω–æ–µ, —Å—á–∞—Å—Ç—å–µ, \", 1, 4, —Å–µ—Ä–∏–∏, –æ–±–∑–æ—Ä, ,, –¥–∞—Ç–∞, –≤—ã—Ö–æ–¥–∞, –Ω–∞, –†–æ—Å—Å–∏—è, 1, ., –ì–ª–∞–≤–Ω—ã–µ, —Ä–æ–ª–∏, –∏—Å–ø–æ–ª–Ω—è—Ç, :, –ú–∞—Ä–∏—è, –ö—É–ª–∏–∫–æ–≤–∞, ,, –Æ—Ä–∏–π, –ë–∞—Ç—É—Ä–∏–Ω, ,, –î–∞–Ω, –†–æ...</td>\n",
       "      <td>[O, O, O, O, B-–Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞, I-–Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞, B-—Å–µ—Ä–∏—è, I-—Å–µ—Ä–∏—è, I-—Å–µ—Ä–∏—è, I-—Å–µ—Ä–∏—è, O, O, B-–î–∞—Ç–∞, O, O, O, O, O, O, O, O, O, O, B-–î–∞—Ç–∞, O, B-–Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞, I-–Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞, O, B-—Å–µ—Ä–∏—è, I-—Å–µ—Ä–∏—è, I-—Å–µ—Ä–∏—è, O, O, O, O, O, B-–ª–æ–∫–∞—Ü–∏—è, O, O, O, O, O, O, B-–ø–µ—Ä—Å–æ–Ω–∞, I-–ø–µ—Ä—Å–æ–Ω–∞, O, B-–ø–µ—Ä—Å–æ–Ω–∞, I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4190</th>\n",
       "      <td>[&lt;, –ù–ê–ó–í–ê–ù–ò–ï, :, &gt;, –≠—Ç–æ–π, –ù–æ—á—å—é, –ì–û–õ–û–í–ö–ò–ù, –ø–æ–±–∏–ª, –≤—Å–µ, –ú–ò–†–û–í–´–ï, –†–ï–ö–û–†–î–´, !, –ù–∞, –≠—Ç–æ, –±—ã–ª–æ, –°—Ç—Ä–∞—à–Ω–æ, –°–º–æ—Ç—Ä–µ—Ç—å, !, &lt;, –û–ü–ò–°–ê–ù–ò–ï, :, &gt;, –í—Å–µ–º, –ø—Ä–∏–≤–µ—Ç, ,, –¥–æ—Ä–æ–≥–∏–µ, –¥—Ä—É–∑—å—è, !, –í—ã, –Ω–∞, –∫–∞–Ω–∞–ª–µ, –ë–µ–∑—É–º–Ω—ã–π, –†–∞—Å—Å–∫–∞–∑—á–∏–∫, 2, ., –°–ú–û–¢–†–ò, –¢–ê–ö–ñ–ï, :, –ú—ç–Ω–Ω–∏, –ü–∞–∫—å—è–æ, –£–Ω–∏—á—Ç–æ–∂–∞–µ—Ç, –ö—Ä—É–ø–Ω—ã—Ö, –ë–æ–∫—Å–µ—Ä–æ–≤, &lt;, LINK, &gt;, –≠—Ç–∏–º, –£...</td>\n",
       "      <td>[O, O, O, O, O, O, B-–ø–µ—Ä—Å–æ–Ω–∞, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-–Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞, I-–Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞, I-–Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞, O, O, O, O, B-–ø–µ—Ä—Å–æ–Ω–∞, I-–ø–µ—Ä—Å–æ–Ω–∞, O, O, O, O, O, O, O, O, B-–ø–µ—Ä—Å–æ–Ω–∞, O, O, O, O, O, O, O, B-–ø–µ—Ä—Å–æ–Ω–∞, I-–ø–µ—Ä—Å–æ–Ω–∞, O, O, O, O, O, O, O, O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                           tokens  \\\n",
       "4812  [<, –ù–ê–ó–í–ê–ù–ò–ï, :, >, –°–∏—Å—Ç–µ–º–∞, –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è, –±–∏–∑–Ω–µ—Å, —Å, WorldVentures, –æ—Ç, –ê–ª–µ–Ω—ã, –ê–Ω—Ç–æ–Ω–µ–Ω–∫–æ, <, –û–ü–ò–°–ê–ù–ò–ï, :, >, –î–æ, –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–≥–æ, –æ—Ç–∫—Ä—ã—Ç–∏—è, –∫–æ–º–ø–∞–Ω–∏–∏, WorldVentures, –≤, –†–æ—Å—Å–∏–∏, –æ—Å—Ç–∞–ª–æ—Å—å, —Å–æ–≤—Å–µ–º, –Ω–µ–º–Ω–æ–≥–æ, –≤—Ä–µ–º–µ–Ω–∏, ., –ü—Ä–∏–º–µ–Ω—è—è, –ø—Ä–æ—Å—Ç—É—é, –∏, –¥—É–ø–ª–∏—Ü–∏—Ä—É–µ–º—É—é, —Å–∏—Å—Ç–µ–º—É, –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è, –±–∏–∑–Ω–µ—Å–∞, ,, –º–æ–∂–Ω–æ, –∑–∞, –∫–æ—Ä–æ...   \n",
       "2915  [<, –ù–ê–ó–í–ê–ù–ò–ï, :, >, –•—Ä—É—Å—Ç–∞–ª—å–Ω–æ–µ, —Å—á–∞—Å—Ç—å–µ, 1, =, 4, —Å–µ—Ä–∏—è, (, –ú–µ–ª–æ–¥—Ä–∞–º–∞, 2021, ), –æ–±–∑–æ—Ä, ,, –¥–∞—Ç–∞, –≤—ã—Ö–æ–¥–∞, <, –û–ü–ò–°–ê–ù–ò–ï, :, >, –ü—Ä–µ–º—å–µ—Ä–∞, 2021, \", –•—Ä—É—Å—Ç–∞–ª—å–Ω–æ–µ, —Å—á–∞—Å—Ç—å–µ, \", 1, 4, —Å–µ—Ä–∏–∏, –æ–±–∑–æ—Ä, ,, –¥–∞—Ç–∞, –≤—ã—Ö–æ–¥–∞, –Ω–∞, –†–æ—Å—Å–∏—è, 1, ., –ì–ª–∞–≤–Ω—ã–µ, —Ä–æ–ª–∏, –∏—Å–ø–æ–ª–Ω—è—Ç, :, –ú–∞—Ä–∏—è, –ö—É–ª–∏–∫–æ–≤–∞, ,, –Æ—Ä–∏–π, –ë–∞—Ç—É—Ä–∏–Ω, ,, –î–∞–Ω, –†–æ...   \n",
       "4190  [<, –ù–ê–ó–í–ê–ù–ò–ï, :, >, –≠—Ç–æ–π, –ù–æ—á—å—é, –ì–û–õ–û–í–ö–ò–ù, –ø–æ–±–∏–ª, –≤—Å–µ, –ú–ò–†–û–í–´–ï, –†–ï–ö–û–†–î–´, !, –ù–∞, –≠—Ç–æ, –±—ã–ª–æ, –°—Ç—Ä–∞—à–Ω–æ, –°–º–æ—Ç—Ä–µ—Ç—å, !, <, –û–ü–ò–°–ê–ù–ò–ï, :, >, –í—Å–µ–º, –ø—Ä–∏–≤–µ—Ç, ,, –¥–æ—Ä–æ–≥–∏–µ, –¥—Ä—É–∑—å—è, !, –í—ã, –Ω–∞, –∫–∞–Ω–∞–ª–µ, –ë–µ–∑—É–º–Ω—ã–π, –†–∞—Å—Å–∫–∞–∑—á–∏–∫, 2, ., –°–ú–û–¢–†–ò, –¢–ê–ö–ñ–ï, :, –ú—ç–Ω–Ω–∏, –ü–∞–∫—å—è–æ, –£–Ω–∏—á—Ç–æ–∂–∞–µ—Ç, –ö—Ä—É–ø–Ω—ã—Ö, –ë–æ–∫—Å–µ—Ä–æ–≤, <, LINK, >, –≠—Ç–∏–º, –£...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                             tags  \n",
       "4812                                                                       [O, O, O, O, O, O, O, O, B-–ø–µ—Ä—Å–æ–Ω–∞, O, B-–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è, I-–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è, O, O, O, O, O, O, O, O, B-–ø–µ—Ä—Å–æ–Ω–∞, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-–ø–µ—Ä—Å–æ–Ω–∞, O, O, B-–ø–µ—Ä—Å–æ–Ω–∞, O, O, O, O, O]  \n",
       "2915  [O, O, O, O, B-–Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞, I-–Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞, B-—Å–µ—Ä–∏—è, I-—Å–µ—Ä–∏—è, I-—Å–µ—Ä–∏—è, I-—Å–µ—Ä–∏—è, O, O, B-–î–∞—Ç–∞, O, O, O, O, O, O, O, O, O, O, B-–î–∞—Ç–∞, O, B-–Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞, I-–Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞, O, B-—Å–µ—Ä–∏—è, I-—Å–µ—Ä–∏—è, I-—Å–µ—Ä–∏—è, O, O, O, O, O, B-–ª–æ–∫–∞—Ü–∏—è, O, O, O, O, O, O, B-–ø–µ—Ä—Å–æ–Ω–∞, I-–ø–µ—Ä—Å–æ–Ω–∞, O, B-–ø–µ—Ä—Å–æ–Ω–∞, I-...  \n",
       "4190  [O, O, O, O, O, O, B-–ø–µ—Ä—Å–æ–Ω–∞, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-–Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞, I-–Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞, I-–Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞, O, O, O, O, B-–ø–µ—Ä—Å–æ–Ω–∞, I-–ø–µ—Ä—Å–æ–Ω–∞, O, O, O, O, O, O, O, O, B-–ø–µ—Ä—Å–æ–Ω–∞, O, O, O, O, O, O, O, B-–ø–µ—Ä—Å–æ–Ω–∞, I-–ø–µ—Ä—Å–æ–Ω–∞, O, O, O, O, O, O, O, O...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 300\n",
    "pd.DataFrame(ner_train).sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fc651f-f5f7-48f6-82d3-acfbb38a5296",
   "metadata": {},
   "source": [
    "#### –ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –ø–æ–ª—É—á–∏–≤—à–∏–µ—Å—è —Ç–µ–≥–∏\n",
    "–ü–æ–¥—Ä–æ–±–Ω–µ–µ –ø–æ—á–∏—Ç–∞—Ç—å –ø—Ä–æ BIO —Ç–µ–≥–∏ –º–æ–∂–Ω–æ —Ç—É—Ç https://datascience.stackexchange.com/questions/63399/what-is-bio-tags-for-creating-custom-ner-named-entity-recognization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d154c93-c038-4c4a-b9ee-8dba7bd1a21c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B-–î–∞—Ç–∞',\n",
       " 'B-–±—Ä–µ–Ω–¥',\n",
       " 'B-–≤–∏–¥ —Å–ø–æ—Ä—Ç–∞',\n",
       " 'B-–≤–∏–¥–µ–æ–∏–≥—Ä–∞',\n",
       " 'B-–∫–æ–º–∞–Ω–¥–∞',\n",
       " 'B-–ª–∏–≥–∞',\n",
       " 'B-–ª–æ–∫–∞—Ü–∏—è',\n",
       " 'B-–º–æ–¥–µ–ª—å',\n",
       " 'B-–Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞',\n",
       " 'B-–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è',\n",
       " 'B-–ø–µ—Ä—Å–æ–Ω–∞',\n",
       " 'B-—Å–µ–∑–æ–Ω',\n",
       " 'B-—Å–µ—Ä–∏—è',\n",
       " 'I-–î–∞—Ç–∞',\n",
       " 'I-–±—Ä–µ–Ω–¥',\n",
       " 'I-–≤–∏–¥ —Å–ø–æ—Ä—Ç–∞',\n",
       " 'I-–≤–∏–¥–µ–æ–∏–≥—Ä–∞',\n",
       " 'I-–∫–æ–º–∞–Ω–¥–∞',\n",
       " 'I-–ª–∏–≥–∞',\n",
       " 'I-–ª–æ–∫–∞—Ü–∏—è',\n",
       " 'I-–º–æ–¥–µ–ª—å',\n",
       " 'I-–Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞',\n",
       " 'I-–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è',\n",
       " 'I-–ø–µ—Ä—Å–æ–Ω–∞',\n",
       " 'I-—Å–µ–∑–æ–Ω',\n",
       " 'I-—Å–µ—Ä–∏—è']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = sorted({label for item in ner_train for label in item['tags']})\n",
    "if 'O' in label_list:\n",
    "    label_list.remove('O')\n",
    "    label_list = ['O'] + label_list\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "803e14bf-5ca9-42bf-8c67-f3718b53d373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4612e752-dc7d-41e6-bede-73e67319aa8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'tags'],\n",
       "        num_rows: 5137\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'tags'],\n",
       "        num_rows: 1285\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_data = DatasetDict({\n",
    "    'train': Dataset.from_pandas(pd.DataFrame(ner_train)),\n",
    "    'test': Dataset.from_pandas(pd.DataFrame(ner_test))\n",
    "})\n",
    "ner_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd286f0c-d748-4289-bf3e-8064e45186cc",
   "metadata": {},
   "source": [
    "### –ó–∞–ø—É—Å—Ç–∏–º –º–æ–¥–µ–ª—å RuBert-tiny - –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π Bert, –ø–æ–≤–µ—Ä—Ö –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω–∞–≤–µ—à–µ–Ω —Å–ª–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "417623f9-c9ac-488f-9e1b-31dbf61e049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer \n",
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "model_checkpoint = \"cointegrated/rubert-tiny\"\n",
    "batch_size = 16\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b58c25f2-b144-4b0c-9dd6-76760d26152f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<', '–ù–ê–ó–í–ê–ù–ò–ï', ':', '>', '–ú–æ—Å–∫–æ–≤—Å–∫–∏–π', '–º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–π', '—Ñ–µ—Å—Ç–∏–≤–∞–ª—å', '–º–∏—Ä–∞', '=', '89', '–∏', '–°—Ç–∞—Å', '–ù–∞–º–∏–Ω', '.', '¬´', '–ì–ª–∞–≤–Ω—ã–π', '–¥–µ–Ω—å', '¬ª', '<', '–û–ü–ò–°–ê–ù–ò–ï', ':', '>', '12', '–∏', '13', '–∏—é–Ω—è', '1989', '–≥–æ–¥–∞', '–Ω–∞', '–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–º', '—Å—Ç–∞–¥–∏–æ–Ω–µ', '–∏–º–µ–Ω–∏', '–í', '.', '–ò', '.', '–õ–µ–Ω–∏–Ω–∞', '—Å–æ—Å—Ç–æ—è–ª—Å—è', '–ø–µ—Ä–≤—ã–π', '–º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–π', '—Ä–æ–∫', '—Ñ–µ—Å—Ç–∏–≤–∞–ª—å', '.', '–ö–æ–Ω—Ü–µ—Ä—Ç', '—Å–æ–±—Ä–∞–ª', '—Å–≤—ã—à–µ', '100', '—Ç—ã—Å—è—á', '–∑—Ä–∏—Ç–µ–ª–µ–π', '.', '–°–æ–≤–µ—Ç—Å–∫–∞—è', '–º–æ–ª–æ–¥–µ–∂—å', '—Ç–æ–≥–¥–∞', '—É–≤–∏–¥–µ–ª–∞', '–∏', '—É—Å–ª—ã—à–∞–ª–∞', '–ø—Ä–∏–∑–Ω–∞–Ω–Ω—ã—Ö', '–º–∏—Ä–æ–≤—ã—Ö', '–∫—É–º–∏—Ä–æ–≤', ':', 'Scorpions', ',', 'Bon', 'Jovi', ',', 'Ozzy', 'Osbourne', ',', 'Cinderella', ',', 'Motley', 'Crue', '.', '–ü—Ä–∏–µ–∑–¥', '–∑–∞–ø–∞–¥–Ω—ã—Ö', '–∑–≤–µ–∑–¥', '–∫–∞–∑–∞–ª—Å—è', '–æ–∂–∏–≤—à–µ–π', '—Ñ–∞–Ω—Ç–∞—Å—Ç–∏–∫–æ–π', '.', '–§–µ—Å—Ç–∏–≤–∞–ª—å', '—Å—Ç–∞–ª', '–Ω–µ', '—Ç–æ–ª—å–∫–æ', '–º—É–∑—ã–∫–∞–ª—å–Ω–æ–π', ',', '–Ω–æ', '–∏', '–≤–∞–∂–Ω–æ–π', '–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–æ–π', '–∞–∫—Ü–∏–µ–π', '.', '–í—Å—è', '–º–∏—Ä–æ–≤–∞—è', '–ø—Ä–µ—Å—Å–∞', '–ø–∏—Å–∞–ª–∞', '–æ', '—Ç–æ–º', ',', '—á—Ç–æ', '–°–°–°–†', '–∏', '–°–®–ê', ',', '–¥–æ–ª–≥–æ–µ', '–≤—Ä–µ–º—è', '–Ω–∞—Ö–æ–¥–∏–≤—à–∏–µ—Å—è', '–≤', '—Å–æ—Å—Ç–æ—è–Ω–∏–∏', '\"', '—Ö–æ–ª–æ–¥–Ω–æ–π', '–≤–æ–π–Ω—ã', '\"', ',', '–Ω–∞–∫–æ–Ω–µ—Ü', '—Ç–æ', '—Å—Ç–∞–ª–∏', '–Ω–∞–ª–∞–∂–∏–≤–∞—Ç—å', '–¥—Ä—É–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ', '–æ—Ç–Ω–æ—à–µ–Ω–∏—è', '–Ω–∞', '–∫—É–ª—å—Ç—É—Ä–Ω–æ–º', '—Ñ—Ä–æ–Ω—Ç–µ', '.', '–ü—Ä–∏–µ–∑–¥', '–∑–∞–ø–∞–¥–Ω—ã—Ö', '–º—É–∑—ã–∫–∞–Ω—Ç–æ–≤', '—Ä–∞–∑—Ä—É—à–∏–ª', '–º–∏—Ñ—ã', '–∏', '—Å—Ç–µ—Ä–µ–æ—Ç–∏–ø—ã', '–æ', '–°–æ–≤–µ—Ç—Å–∫–æ–º', '–°–æ—é–∑–µ', ',', '–∫–∞–∫', '–æ', '—Å—É—Ä–æ–≤–æ–π', '–∏', '–∑–∞–∫—Ä—ã—Ç–æ–π', '—Å—Ç—Ä–∞–Ω–µ', '.', '–ù–æ', '—á—Ç–æ', '–æ—Å—Ç–∞–ª–æ—Å—å', '–∑–∞', '–∫–∞–¥—Ä–æ–º', '—ç—Ç–æ–π', '–º—É–∑—ã–∫–∞–ª—å–Ω–æ–π', '—Ä–µ–≤–æ–ª—é—Ü–∏–∏', '?', '–ì–ª–∞–≤–Ω—ã–π', '–æ—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä', '—Ñ–µ—Å—Ç–∏–≤–∞–ª—è', '–º—É–∑—ã–∫–∞–Ω—Ç', '–∏', '–ø—Ä–æ–¥—é—Å–µ—Ä', '–°—Ç–∞—Å', '–ù–∞–º–∏–Ω', ',', '–∞', '—Ç–∞–∫–∂–µ', '–Ω–µ–∫–æ—Ç–æ—Ä—ã–µ', '—É—á–∞—Å—Ç–Ω–∏–∫–∏', '—Å–æ–≥–ª–∞—Å–∏–ª–∏—Å—å', '–ø–æ–¥–µ–ª–∏—Ç—å—Å—è', '—Å–≤–æ–∏–º–∏', '–ª–∏—á–Ω—ã–º–∏', '–≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è–º–∏', '.']\n"
     ]
    }
   ],
   "source": [
    "example = ner_train[5]\n",
    "print(example[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40bf5c30-7ee2-46d3-9733-da3ff8b803fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '<', '–ù', '##–ê–ó', '##–í', '##–ê–ù', '##–ò', '##–ï', ':', '>', '–ú–æ—Å–∫–æ–≤—Å–∫–∏–π', '–º–µ–∂–¥—É', '##–Ω–∞—Ä–æ–¥–Ω—ã–π', '—Ñ–µ—Å—Ç–∏–≤–∞–ª—å', '–º–∏—Ä–∞', '=', '89', '–∏', '–°', '##—Ç–∞—Å', '–ù–∞', '##–º–∏–Ω', '.', '¬´', '–ì–ª–∞–≤–Ω—ã–π', '–¥–µ–Ω—å', '¬ª', '<', '–û', '##–ü', '##–ò', '##–°', '##–ê–ù', '##–ò', '##–ï', ':', '>', '12', '–∏', '13', '–∏—é–Ω—è', '1989', '–≥–æ–¥–∞', '–Ω–∞', '–¶–µ–Ω—Ç—Ä', '##–∞–ª—å–Ω–æ–º', '—Å—Ç–∞–¥–∏–æ–Ω', '##–µ', '–∏–º–µ–Ω–∏', '–í', '.', '–ò', '.', '–õ–µ–Ω–∏–Ω–∞', '—Å–æ—Å—Ç–æ—è–ª—Å—è', '–ø–µ—Ä–≤—ã–π', '–º–µ–∂–¥—É', '##–Ω–∞—Ä–æ–¥–Ω—ã–π', '—Ä–æ–∫', '—Ñ–µ—Å—Ç–∏–≤–∞–ª—å', '.', '–ö', '##–æ–Ω', '##—Ü–µ—Ä', '##—Ç', '—Å–æ', '##–±—Ä–∞–ª', '—Å–≤—ã—à–µ', '100', '—Ç—ã—Å—è—á', '–∑—Ä–∏—Ç–µ–ª–µ–π', '.', '–°–æ–≤–µ—Ç—Å–∫–∞—è', '–º', '##–æ–ª–æ', '##–¥–µ', '##–∂', '##—å', '—Ç–æ–≥–¥–∞', '—É', '##–≤–∏–¥', '##–µ–ª–∞', '–∏', '—É', '##—Å–ª', '##—ã—à', '##–∞–ª–∞', '–ø—Ä–∏–∑–Ω–∞–Ω', '##–Ω—ã—Ö', '–º–∏—Ä', '##–æ–≤—ã—Ö', '–∫', '##—É–º–∏', '##—Ä–æ–≤', ':', 'Sc', '##orp', '##ions', ',', 'Bon', 'Jovi', ',', 'Oz', '##zy', 'Os', '##bour', '##ne', ',', 'Ci', '##nder', '##ella', ',', 'Mot', '##ley', 'C', '##rue', '.', '–ü—Ä–∏', '##–µ–∑–¥', '–∑–∞–ø–∞–¥', '##–Ω—ã—Ö', '–∑–≤', '##–µ–∑–¥', '–∫–∞–∑', '##–∞–ª—Å—è', '–æ', '##–∂–∏–≤', '##—à–µ–π', '—Ñ', '##–∞–Ω—Ç', '##–∞—Å—Ç', '##–∏–∫–æ–π', '.', '–§', '##–µ—Å—Ç–∏–≤–∞–ª', '##—å', '—Å—Ç–∞–ª', '–Ω–µ', '—Ç–æ–ª—å–∫–æ', '–º—É–∑—ã–∫–∞–ª—å–Ω–æ–π', ',', '–Ω–æ', '–∏', '–≤–∞', '##–∂–Ω–æ–π', '–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–æ–π', '–∞', '##–∫', '##—Ü–∏–µ–π', '.', '–í', '##—Å—è', '–º–∏—Ä', '##–æ–≤–∞—è', '–ø—Ä–µ', '##—Å—Å–∞', '–ø–∏—Å–∞–ª', '##–∞', '–æ', '—Ç–æ–º', ',', '—á—Ç–æ', '–°–°–°–†', '–∏', '–°–®–ê', ',', '–¥–æ–ª–≥–æ', '##–µ', '–≤—Ä–µ–º—è', '–Ω–∞', '##—Ö–æ–¥–∏–≤', '##—à–∏–µ—Å—è', '–≤', '—Å–æ—Å—Ç–æ—è–Ω–∏–∏', '\"', '—Ö', '##–æ–ª–æ', '##–¥–Ω–æ–π', '–≤–æ–π–Ω—ã', '\"', ',', '–Ω–∞–∫–æ–Ω–µ—Ü', '—Ç–æ', '—Å—Ç–∞–ª–∏', '–Ω–∞', '##–ª–∞', '##–∂–∏–≤–∞—Ç—å', '–¥—Ä', '##—É', '##–∂–µ', '##—Å—Ç–≤–µ–Ω–Ω—ã–µ', '–æ—Ç–Ω–æ—à–µ–Ω–∏—è', '–Ω–∞', '–∫—É–ª—å—Ç—É—Ä', '##–Ω–æ–º', '—Ñ—Ä–æ–Ω—Ç–µ', '.', '–ü—Ä–∏', '##–µ–∑–¥', '–∑–∞–ø–∞–¥', '##–Ω—ã—Ö', '–º—É–∑—ã–∫–∞', '##–Ω—Ç–æ–≤', '—Ä–∞–∑', '##—Ä—É', '##—à–∏–ª', '–º–∏', '##—Ñ—ã', '–∏', '—Å—Ç', '##–µ—Ä–µ', '##–æ—Ç–∏', '##–ø—ã', '–æ', '–°–æ–≤–µ—Ç', '##—Å–∫–æ–º', '–°–æ—é–∑', '##–µ', ',', '–∫–∞–∫', '–æ', '—Å—É', '##—Ä–æ–≤–æ', '##–π', '–∏', '–∑–∞', '##–∫—Ä—ã—Ç', '##–æ–π', '—Å—Ç—Ä–∞–Ω–µ', '.', '–ù–æ', '—á—Ç–æ', '–æ—Å', '##—Ç–∞–ª', '##–æ—Å—å', '–∑–∞', '–∫–∞', '##–¥—Ä–æ–º', '—ç—Ç–æ–π', '–º—É–∑—ã–∫–∞–ª—å–Ω–æ–π', '—Ä–µ–≤–æ–ª—é—Ü–∏–∏', '?', '–ì–ª–∞–≤–Ω—ã–π', '–æ—Ä–≥–∞–Ω–∏', '##–∑–∞—Ç–æ—Ä', '—Ñ–µ—Å—Ç–∏–≤–∞–ª—è', '–º—É–∑—ã–∫–∞', '##–Ω—Ç', '–∏', '–ø—Ä–æ–¥—é—Å–µ—Ä', '–°', '##—Ç–∞—Å', '–ù–∞', '##–º–∏–Ω', ',', '–∞', '—Ç–∞–∫–∂–µ', '–Ω–µ–∫–æ—Ç–æ—Ä—ã–µ', '—É—á–∞—Å—Ç–Ω–∏–∫–∏', '—Å–æ', '##–≥–ª–∞', '##—Å–∏–ª–∏', '##—Å—å', '–ø–æ–¥', '##–µ–ª–∏', '##—Ç—å—Å—è', '—Å–≤–æ–∏–º–∏', '–ª–∏', '##—á–Ω—ã–º–∏', '–≤–æ', '##—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è', '##–º–∏', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4163cecf-a14b-4c26-9273-3fa400055163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170, 274)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(example[\"tags\"]), len(tokenized_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba2321f2-8b2e-4178-bbd8-0b0a803aedd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 1, 1, 1, 1, 1, 1, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 11, 12, 12, 13, 14, 15, 16, 17, 18, 19, 19, 19, 19, 19, 19, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 29, 30, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 39, 40, 41, 42, 43, 43, 43, 43, 44, 44, 45, 46, 47, 48, 49, 50, 51, 51, 51, 51, 51, 52, 53, 53, 53, 54, 55, 55, 55, 55, 56, 56, 57, 57, 58, 58, 58, 59, 60, 60, 60, 61, 62, 63, 64, 65, 65, 66, 66, 66, 67, 68, 68, 68, 69, 70, 70, 71, 71, 72, 73, 73, 74, 74, 75, 75, 76, 76, 77, 77, 77, 78, 78, 78, 78, 79, 80, 80, 80, 81, 82, 83, 84, 85, 86, 87, 88, 88, 89, 90, 90, 90, 91, 92, 92, 93, 93, 94, 94, 95, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 104, 105, 106, 106, 106, 107, 108, 109, 110, 110, 110, 111, 112, 113, 114, 115, 116, 117, 117, 117, 118, 118, 118, 118, 119, 120, 121, 121, 122, 123, 124, 124, 125, 125, 126, 126, 127, 127, 127, 128, 128, 129, 130, 130, 130, 130, 131, 132, 132, 133, 133, 134, 135, 136, 137, 137, 137, 138, 139, 139, 139, 140, 141, 142, 143, 144, 144, 144, 145, 146, 146, 147, 148, 149, 150, 151, 152, 152, 153, 154, 154, 155, 156, 157, 157, 158, 158, 159, 160, 161, 162, 163, 164, 164, 164, 164, 165, 165, 165, 166, 167, 167, 168, 168, 168, 169, None]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_input.word_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17363352-e562-450a-a54f-f30cf6a3ede5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274 274\n"
     ]
    }
   ],
   "source": [
    "word_ids = tokenized_input.word_ids()\n",
    "aligned_labels = [-100 if i is None else example[\"tags\"][i] for i in word_ids]\n",
    "print(len(aligned_labels), len(tokenized_input[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa21220-e351-4259-83c5-c60cdb73dfe2",
   "metadata": {},
   "source": [
    "#### –£ Bert —Å–≤–æ–π —Å–æ–±—Å–≤–µ–Ω–Ω—ã–π —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞–∑–±–∏–≤–∞–µ—Ç —Å–ª–æ–≤–∞ –Ω–∞ –º–µ–ª–∫–∏–µ —Ç–æ–∫–µ–Ω—ã, –ø–æ—ç—Ç–æ–º—É –Ω–∞–º –Ω—É–∂–Ω–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å —Ç–æ–∫–µ–Ω—ã –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å–≤—É—é—â–∏–µ –∏–º –Ω–µ—Ä—ã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80cb5952-a6aa-4032-8940-ec397d2bb68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples, label_all_tokens=True):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples['tags']):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        label_ids = [label_list.index(idx) if isinstance(idx, str) else idx for idx in label_ids]\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2735bc96-92cc-4361-8c44-583eabf4bb77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[2, 32, 293, 16218, 8117, 20795, 8759, 14386, 30, 34, 16992, 12449, 19314, 9147, 705, 19062, 1211, 2179, 15349, 603, 32, 294, 3932, 8759, 3330, 20795, 8759, 14386, 30, 34, 294, 18147, 5972, 2386, 1928, 733, 22970, 613, 17565, 29484, 15479, 12122, 18398, 13334, 1, 16992, 12449, 19314, 9147, 705, 19062, 1211, 2179, 15349, 603, 18, 282, 3200, 860, 20727, 12029, 4375, 29463, 2013, 2262, 18, 294, 15735, 29137, 320, 18029, 18398, 24952, 753, 705, 11316, 4307, 329, 22067, 12427, 283, 4297, 292, 29172, 3330, 1928, 705, 13790, 294, 22797, 1768, 10203, 761, 13951, 3243, 2535, 2641, 18, 3]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_and_align_labels(ner_data['train'][1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39acdcaf-7f6b-467f-a143-9820b4f13ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5137 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1285 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = ner_data.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cce292-6c29-43be-909b-adb1536b6ebf",
   "metadata": {},
   "source": [
    "#### –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ª–æ–≤–∞—Ä–∏–∫ —Å–æ–æ—Ç–≤–µ—Å—Ç–≤–∏—è —Ç–µ–≥–∞ –∏ –µ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ –≤–Ω—É—Ç—Ä–∏ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5edcbfc0-6bbd-4be1-9da7-6fe6e348753e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label_list))\n",
    "model.config.id2label = dict(enumerate(label_list))\n",
    "model.config.label2id = {v: k for k, v in model.config.id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7118790-3483-4fca-b3d9-950287202381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –æ–±—ä–µ–∫—Ç –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –±–∞—Ç—á–µ–π\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcbfb44-68cc-42d1-98da-1a12a87aac10",
   "metadata": {},
   "source": [
    "### –í –∫–∞—á–µ—Å—Ç–≤–µ –º–µ—Ç—Ä–∏–∫ –≤–æ–∑—å–º–µ–º precision, recall, accuracy, –¥–ª—è —ç—Ç–æ–≥–æ –≤–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ø–æ–¥ Ner –∑–∞–¥–∞—á—É –±–∏–±–ª–∏–æ—Ç–µ–∫—É seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bcc2483f-93f8-4207-92e2-1f91217a42d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pw/qs4ys1kd68sbr86_46f_tgz80000gp/T/ipykernel_20329/152412463.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"seqeval\")\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73d999fc-9eeb-4cd3-b358-762fdfd80f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'–±—Ä–µ–Ω–¥': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " '–ª–æ–∫–∞—Ü–∏—è': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'overall_precision': 1.0,\n",
       " 'overall_recall': 1.0,\n",
       " 'overall_f1': 1.0,\n",
       " 'overall_accuracy': 1.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = ner_train[4]\n",
    "labels = example['tags']\n",
    "metric.compute(predictions=[labels], references=[labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac26e3f4-52f8-4d98-b629-cd2b32fd8c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    \"ner\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy='no',\n",
    "    report_to='none',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1dbfdd9-443e-4b5e-90a7-e9abac9d4976",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Placeholder storage has not been allocated on MPS device!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pw/qs4ys1kd68sbr86_46f_tgz80000gp/T/ipykernel_20329/2760453783.py\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.venv/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3053\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   3054\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3055\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3244\u001b[0m             \u001b[0;31m# Prediction step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3245\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3246\u001b[0m             \u001b[0minputs_decode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_inputs_for_metrics\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mprediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   3501\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhas_labels\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mloss_without_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3502\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3503\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3504\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2782\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2783\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2784\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2785\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2786\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1756\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1758\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1759\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1760\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         embedding_output = self.embeddings(\n\u001b[0m\u001b[1;32m   1014\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/lib/python3.9/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[0;32m~/.venv/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2231\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2233\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Placeholder storage has not been allocated on MPS device!"
     ]
    }
   ],
   "source": [
    "# —á—Ç–æ –º—ã –≤–∏–¥–∏–º –±–µ–∑ –¥–æ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels, zero_division=0)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0f88a098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: torch in /Users/gskvortsov/.venv/lib/python3.9/site-packages (2.1.0)\n",
      "Requirement already satisfied: torchvision in /Users/gskvortsov/.venv/lib/python3.9/site-packages (0.16.0)\n",
      "Collecting torchaudio\n",
      "  Obtaining dependency information for torchaudio from https://files.pythonhosted.org/packages/9e/e2/812b1a2a5ec34fe7c0a5cf11b4e62709172fd71783cbc8b7875e3051e8a5/torchaudio-2.1.0-cp39-cp39-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading torchaudio-2.1.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: filelock in /Users/gskvortsov/.venv/lib/python3.9/site-packages (from torch) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/gskvortsov/.venv/lib/python3.9/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /Users/gskvortsov/.venv/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/gskvortsov/.venv/lib/python3.9/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/gskvortsov/.venv/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/gskvortsov/.venv/lib/python3.9/site-packages (from torch) (2023.3.0)\n",
      "Requirement already satisfied: numpy in /Users/gskvortsov/.venv/lib/python3.9/site-packages (from torchvision) (1.25.2)\n",
      "Requirement already satisfied: requests in /Users/gskvortsov/.venv/lib/python3.9/site-packages (from torchvision) (2.25.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/gskvortsov/.venv/lib/python3.9/site-packages (from torchvision) (9.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/gskvortsov/.venv/lib/python3.9/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/gskvortsov/.venv/lib/python3.9/site-packages (from requests->torchvision) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/gskvortsov/.venv/lib/python3.9/site-packages (from requests->torchvision) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/gskvortsov/.venv/lib/python3.9/site-packages (from requests->torchvision) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/gskvortsov/.venv/lib/python3.9/site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/gskvortsov/.venv/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading torchaudio-2.1.0-cp39-cp39-macosx_11_0_arm64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m43.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: torchaudio\n",
      "Successfully installed torchaudio-2.1.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9441d5bb-9bf3-4f3d-ad2d-24e577ed5418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from transformers.trainer import logger as noisy_logger\n",
    "noisy_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf85ec22-19e5-4e10-be46-bf99fb57a815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –î–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è –±–µ—Ä—Ç–∞ –º–æ–∂–Ω–æ —ç–∫—Å–ø–µ—Ä–µ–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Å –∑–∞–º–æ—Ä–æ–∑–∫–æ–π/—Ä–∞–∑–º–æ—Ä–æ–∑–∫–æ–π —Ä–∞–∑–Ω—ã—Ö —Å–ª–æ–µ–≤, –∑–¥–µ—Å—å –º—ã –æ—Å—Ç–∞–≤–∏–º –≤—Å–µ —Å–ª–æ–∏ —Ä–∞–∑–º–æ—Ä–æ–∂–µ–Ω–Ω—ã–º–∏ \n",
    "# –î–ª—è –±—ã—Å—Ç—Ä–æ—Ç—ã –æ–±—É—á–µ–Ω–∏—è –º–æ–∂–Ω–æ –∑–∞–º–æ—Ä–æ–∑–∏—Ç—å –≤—Å—é –±–µ—Ä—Ç–æ–≤—É—é —á–∞—Å—Ç—å, –∫—Ä–æ–º–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞, –Ω–æ —Ç–æ–≥–¥–∞ –∫–∞—á–µ—Å–≤—Ç–æ –±—É–¥–µ—Ç –ø–æ—Ö—É–∂–µ\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b907071-d37c-4d5b-8ce6-57aea13663bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    \"ner\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy='no',\n",
    "    report_to='none',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5195e9a2-2c31-47f0-b539-512c486e99dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d12a5c-639b-4d84-a8c0-92b52b3cdf60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a36b49-d3d3-4dcc-bb33-5b3cbdb555ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33edf3c3-70e7-49c4-a9b6-842a0eb4f014",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# –ü–æ—Å—á–∏—Ç–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –æ—Ç–ª–æ–∂–µ–Ω–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ\n",
    "\n",
    "predictions, labels, _ = trainer.predict(tokenized_datasets[\"test\"])\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "# Remove ignored index (special tokens)\n",
    "true_predictions = [\n",
    "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "true_labels = [\n",
    "    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "\n",
    "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de83f349-9ba5-42fe-8f5f-780c6f26d918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eead2c66-11d0-4cb8-ab58-530d2524b941",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm = pd.DataFrame(\n",
    "    confusion_matrix(sum(true_labels, []), sum(true_predictions, []), labels=label_list),\n",
    "    index=label_list,\n",
    "    columns=label_list\n",
    ")\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cd985f-b4f6-4e6f-b28a-a54bf2e59c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('ner_bert.bin')\n",
    "tokenizer.save_pretrained('ner_bert.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea14342-bbf6-40c0-aa44-3c2db9c8215b",
   "metadata": {},
   "source": [
    "### –ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2519aaaf-02b8-4f66-885c-8930073508a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = ' '.join(ner_train[25]['tokens'])\n",
    "text = ner_train[25]['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "daee5bc1-634c-4bde-aa51-64425aba5931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(model=model, tokenizer=tokenizer, task='ner', aggregation_strategy='average', device='cpu')\n",
    "\n",
    "def predict_ner(text, tokenizer, model, pipe, verbose=True):\n",
    "    tokens = tokenizer(text, truncation=True, is_split_into_words=True, return_tensors='pt')\n",
    "    tokens = {k: v.to(model.device) for k, v in tokens.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pred = model(**tokens)\n",
    "    # print(pred.logits.shape)\n",
    "    indices = pred.logits.argmax(dim=-1)[0].cpu().numpy()\n",
    "    token_text = tokenizer.convert_ids_to_tokens(tokens['input_ids'][0])\n",
    "    labels = []\n",
    "    for t, idx in zip(token_text, indices):\n",
    "        if '##' not in t:\n",
    "            labels.append(label_list[idx])\n",
    "        if verbose:    \n",
    "            print(f'{t:15s} {label_list[idx]:10s}')\n",
    "    return text, pipe(text), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93a3a44-a23d-4615-8885-63da60761d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_ner(text, tokenizer, model, pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3f580a-4542-42ea-98f4-de4a89fed35d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b333764e-e82d-4c8f-9f89-8390f92da7cb",
   "metadata": {},
   "source": [
    "### –¢–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ —É –≤–∞—Å –ø–æ–∫–∞ –Ω–µ—Ç, –ø–æ –∫–æ—Ç–æ—Ä–æ–º—É –±—É–¥–µ—Ç —Å—á–∏—Ç–∞—Ç—å—Å—è –º–µ—Ç—Ä–∏–∫–∞ –Ω–∞ –ª–∏–¥–µ—Ä–±–æ—Ä–¥–µ, –Ω–æ –ø—Ä–æ–≥–æ–Ω–∏–º –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞ —á–µ—Ä–µ–∑ –Ω–∞—à—É –æ—Ç–ª–æ–∂–µ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫—É, —á—Ç–æ–±—ã –ø–æ–Ω—è—Ç—å —Ñ–æ—Ä–º–∞—Ç –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.\n",
    "–í–ê–ñ–ù–û: –≤ —Ç–µ—Å—Ç–æ–≤–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ —É –≤–∞—Å –±—É–¥–µ—Ç —Ç–µ—Å—Ç –≤ —Ç–æ–º –∂–µ —Ñ–æ—Ä–º–∞—Ç–µ, —á—Ç–æ –æ–Ω –±—ã–ª –≤ —Ç—Ä–µ–π–Ω–µ 'video_info', –≤ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º —Å–∞–±–º–∏—à–µ–Ω–µ —ç—Ç—É –∫–æ–ª–æ–Ω–∫—É –∏ –∏–Ω–¥–µ–∫—Å—ã –º–µ–Ω—è—Ç—å –Ω–µ–ª—å–∑—è, –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç —Ç–æ–ª—å–∫–æ –∑–∞–ø–æ–ª–Ω–∏—Ç—å –∫–æ–ª–æ–Ω–∫—É 'entities_prediction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5ccfdd-46aa-49a0-af51-c7adea1d0237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "submission = pd.DataFrame(columns=[['video_info', 'entities_prediction']])\n",
    "submission['entities_prediction'] = submission['entities_prediction'].astype('object')\n",
    "def sample_submission(text, tokenizer, model, pipe, submission):\n",
    "    for i, elem in tqdm(enumerate(ner_test)):\n",
    "        _, _, labels = predict_ner(elem['tokens'], tokenizer, model, pipe, verbose=False)\n",
    "        submission.loc[i, 'video_info'] = elem\n",
    "\n",
    "        submission.loc[i, 'entities_prediction'] = [[label] for label in labels]\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958310b4-09fa-41bd-b888-b4364be3f397",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = sample_submission(text, tokenizer, model, pipe, submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0588b1-6e42-4f37-bfe6-2f695cb6971e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15cdcc7-3750-46ad-abea-36fc712feb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ner_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
